{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Compare 3 configurations for the activation function."
      ],
      "metadata": {
        "id": "_C_JvY2pqvc6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGHtO8dMgldr"
      },
      "outputs": [],
      "source": [
        "import torch as torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),])\n",
        "\n",
        "mnist_trainset = datasets.MNIST(root= './data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
        "\n",
        "mnist_testset = datasets.MNIST(root= './data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAIXeR0HsSh7",
        "outputId": "02a7f604-2643-48b0-9abe-5340f112b648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 104762713.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 34769142.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 18240611.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5688423.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will train and evaluate three different models to compare different configurations with three different activation functions."
      ],
      "metadata": {
        "id": "GNF5opsguHtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. ReLU activation function"
      ],
      "metadata": {
        "id": "HBcm1h1IuXSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ReLU activation function\n",
        "\n",
        "class ReLU_model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ReLU_model, self).__init__()\n",
        "    self.relu1 = nn.Linear(28*28, 128)\n",
        "    self.relu2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28*28)\n",
        "    x = torch.relu(self.relu1(x))\n",
        "    x = self.relu2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "T-nnLeE_uJ-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Sigmoid activation function"
      ],
      "metadata": {
        "id": "KYO86a_3zTkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sigmoid activation function\n",
        "\n",
        "class Sigmoid_model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Sigmoid_model, self).__init__()\n",
        "    self.sigmoid1 = nn.Linear(28*28, 128)\n",
        "    self.sigmoid2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28*28)\n",
        "    x = torch.sigmoid(self.sigmoid1(x))\n",
        "    x = self.sigmoid2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ZkI0uIeOzYI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Softmax activation function"
      ],
      "metadata": {
        "id": "nIGIFhkA0HV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax activation function\n",
        "\n",
        "class Softmax_model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Softmax_model, self).__init__()\n",
        "    self.softmax1 = nn.Linear(28*28, 128)\n",
        "    self.softmax2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28*28)\n",
        "    x = self.softmax1(x)\n",
        "    x = torch.softmax(x, dim=1)\n",
        "    x = self.softmax2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "OUwQOKtn0epB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-entropy loss function."
      ],
      "metadata": {
        "id": "_TWey9Zy2rv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_el = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.01\n",
        "momentum = 0.9\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "THZ7xyDc24d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [ReLU_model(), Sigmoid_model(), Softmax_model()]\n",
        "accurate = []\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "  print(f'Model {i+1}')\n",
        "  optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for j, data in enumerate(train_loader, 0):\n",
        "      inputs, labels = data\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      loss = cross_el(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      if j % 100 == 99:\n",
        "        print(f'[epoch: {epoch + 1}, {j+1}] loss: {running_loss / 100:.3f}')\n",
        "        running_loss = 0.0\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      images, labels = data\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  accuracy = 100 * correct / total\n",
        "  print(f'Accuracy: {accuracy}%')\n",
        "  accurate.append(accuracy)\n",
        "\n",
        "print('Accurate:', accurate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxBCYzDs3Of-",
        "outputId": "7b359257-ce44-4c10-fb04-dc354053d5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1\n",
            "[epoch: 1, 100] loss: 1.324\n",
            "[epoch: 1, 200] loss: 0.784\n",
            "[epoch: 1, 300] loss: 0.712\n",
            "[epoch: 1, 400] loss: 0.628\n",
            "[epoch: 1, 500] loss: 0.610\n",
            "[epoch: 1, 600] loss: 0.610\n",
            "[epoch: 1, 700] loss: 0.552\n",
            "[epoch: 1, 800] loss: 0.514\n",
            "[epoch: 1, 900] loss: 0.478\n",
            "[epoch: 1, 1000] loss: 0.442\n",
            "[epoch: 1, 1100] loss: 0.471\n",
            "[epoch: 1, 1200] loss: 0.476\n",
            "[epoch: 1, 1300] loss: 0.439\n",
            "[epoch: 1, 1400] loss: 0.483\n",
            "[epoch: 1, 1500] loss: 0.421\n",
            "[epoch: 1, 1600] loss: 0.494\n",
            "[epoch: 1, 1700] loss: 0.417\n",
            "[epoch: 1, 1800] loss: 0.441\n",
            "[epoch: 1, 1900] loss: 0.481\n",
            "[epoch: 1, 2000] loss: 0.428\n",
            "[epoch: 1, 2100] loss: 0.381\n",
            "[epoch: 1, 2200] loss: 0.379\n",
            "[epoch: 1, 2300] loss: 0.348\n",
            "[epoch: 1, 2400] loss: 0.421\n",
            "[epoch: 1, 2500] loss: 0.367\n",
            "[epoch: 1, 2600] loss: 0.339\n",
            "[epoch: 1, 2700] loss: 0.393\n",
            "[epoch: 1, 2800] loss: 0.401\n",
            "[epoch: 1, 2900] loss: 0.311\n",
            "[epoch: 1, 3000] loss: 0.355\n",
            "[epoch: 1, 3100] loss: 0.367\n",
            "[epoch: 1, 3200] loss: 0.347\n",
            "[epoch: 1, 3300] loss: 0.307\n",
            "[epoch: 1, 3400] loss: 0.354\n",
            "[epoch: 1, 3500] loss: 0.322\n",
            "[epoch: 1, 3600] loss: 0.387\n",
            "[epoch: 1, 3700] loss: 0.346\n",
            "[epoch: 1, 3800] loss: 0.375\n",
            "[epoch: 1, 3900] loss: 0.381\n",
            "[epoch: 1, 4000] loss: 0.373\n",
            "[epoch: 1, 4100] loss: 0.329\n",
            "[epoch: 1, 4200] loss: 0.351\n",
            "[epoch: 1, 4300] loss: 0.366\n",
            "[epoch: 1, 4400] loss: 0.320\n",
            "[epoch: 1, 4500] loss: 0.308\n",
            "[epoch: 1, 4600] loss: 0.299\n",
            "[epoch: 1, 4700] loss: 0.332\n",
            "[epoch: 1, 4800] loss: 0.309\n",
            "[epoch: 1, 4900] loss: 0.338\n",
            "[epoch: 1, 5000] loss: 0.324\n",
            "[epoch: 1, 5100] loss: 0.245\n",
            "[epoch: 1, 5200] loss: 0.300\n",
            "[epoch: 1, 5300] loss: 0.311\n",
            "[epoch: 1, 5400] loss: 0.346\n",
            "[epoch: 1, 5500] loss: 0.321\n",
            "[epoch: 1, 5600] loss: 0.332\n",
            "[epoch: 1, 5700] loss: 0.271\n",
            "[epoch: 1, 5800] loss: 0.264\n",
            "[epoch: 1, 5900] loss: 0.251\n",
            "[epoch: 1, 6000] loss: 0.373\n",
            "[epoch: 2, 100] loss: 0.297\n",
            "[epoch: 2, 200] loss: 0.327\n",
            "[epoch: 2, 300] loss: 0.271\n",
            "[epoch: 2, 400] loss: 0.271\n",
            "[epoch: 2, 500] loss: 0.259\n",
            "[epoch: 2, 600] loss: 0.299\n",
            "[epoch: 2, 700] loss: 0.255\n",
            "[epoch: 2, 800] loss: 0.310\n",
            "[epoch: 2, 900] loss: 0.348\n",
            "[epoch: 2, 1000] loss: 0.267\n",
            "[epoch: 2, 1100] loss: 0.367\n",
            "[epoch: 2, 1200] loss: 0.322\n",
            "[epoch: 2, 1300] loss: 0.294\n",
            "[epoch: 2, 1400] loss: 0.251\n",
            "[epoch: 2, 1500] loss: 0.238\n",
            "[epoch: 2, 1600] loss: 0.306\n",
            "[epoch: 2, 1700] loss: 0.318\n",
            "[epoch: 2, 1800] loss: 0.206\n",
            "[epoch: 2, 1900] loss: 0.242\n",
            "[epoch: 2, 2000] loss: 0.328\n",
            "[epoch: 2, 2100] loss: 0.268\n",
            "[epoch: 2, 2200] loss: 0.254\n",
            "[epoch: 2, 2300] loss: 0.251\n",
            "[epoch: 2, 2400] loss: 0.297\n",
            "[epoch: 2, 2500] loss: 0.240\n",
            "[epoch: 2, 2600] loss: 0.251\n",
            "[epoch: 2, 2700] loss: 0.263\n",
            "[epoch: 2, 2800] loss: 0.345\n",
            "[epoch: 2, 2900] loss: 0.256\n",
            "[epoch: 2, 3000] loss: 0.240\n",
            "[epoch: 2, 3100] loss: 0.281\n",
            "[epoch: 2, 3200] loss: 0.252\n",
            "[epoch: 2, 3300] loss: 0.316\n",
            "[epoch: 2, 3400] loss: 0.272\n",
            "[epoch: 2, 3500] loss: 0.259\n",
            "[epoch: 2, 3600] loss: 0.205\n",
            "[epoch: 2, 3700] loss: 0.273\n",
            "[epoch: 2, 3800] loss: 0.300\n",
            "[epoch: 2, 3900] loss: 0.315\n",
            "[epoch: 2, 4000] loss: 0.221\n",
            "[epoch: 2, 4100] loss: 0.255\n",
            "[epoch: 2, 4200] loss: 0.266\n",
            "[epoch: 2, 4300] loss: 0.277\n",
            "[epoch: 2, 4400] loss: 0.226\n",
            "[epoch: 2, 4500] loss: 0.351\n",
            "[epoch: 2, 4600] loss: 0.196\n",
            "[epoch: 2, 4700] loss: 0.214\n",
            "[epoch: 2, 4800] loss: 0.242\n",
            "[epoch: 2, 4900] loss: 0.211\n",
            "[epoch: 2, 5000] loss: 0.205\n",
            "[epoch: 2, 5100] loss: 0.341\n",
            "[epoch: 2, 5200] loss: 0.274\n",
            "[epoch: 2, 5300] loss: 0.234\n",
            "[epoch: 2, 5400] loss: 0.222\n",
            "[epoch: 2, 5500] loss: 0.232\n",
            "[epoch: 2, 5600] loss: 0.208\n",
            "[epoch: 2, 5700] loss: 0.266\n",
            "[epoch: 2, 5800] loss: 0.175\n",
            "[epoch: 2, 5900] loss: 0.297\n",
            "[epoch: 2, 6000] loss: 0.215\n",
            "[epoch: 3, 100] loss: 0.226\n",
            "[epoch: 3, 200] loss: 0.233\n",
            "[epoch: 3, 300] loss: 0.212\n",
            "[epoch: 3, 400] loss: 0.241\n",
            "[epoch: 3, 500] loss: 0.250\n",
            "[epoch: 3, 600] loss: 0.246\n",
            "[epoch: 3, 700] loss: 0.200\n",
            "[epoch: 3, 800] loss: 0.195\n",
            "[epoch: 3, 900] loss: 0.247\n",
            "[epoch: 3, 1000] loss: 0.249\n",
            "[epoch: 3, 1100] loss: 0.181\n",
            "[epoch: 3, 1200] loss: 0.146\n",
            "[epoch: 3, 1300] loss: 0.266\n",
            "[epoch: 3, 1400] loss: 0.226\n",
            "[epoch: 3, 1500] loss: 0.184\n",
            "[epoch: 3, 1600] loss: 0.177\n",
            "[epoch: 3, 1700] loss: 0.180\n",
            "[epoch: 3, 1800] loss: 0.286\n",
            "[epoch: 3, 1900] loss: 0.212\n",
            "[epoch: 3, 2000] loss: 0.214\n",
            "[epoch: 3, 2100] loss: 0.291\n",
            "[epoch: 3, 2200] loss: 0.211\n",
            "[epoch: 3, 2300] loss: 0.277\n",
            "[epoch: 3, 2400] loss: 0.201\n",
            "[epoch: 3, 2500] loss: 0.225\n",
            "[epoch: 3, 2600] loss: 0.248\n",
            "[epoch: 3, 2700] loss: 0.246\n",
            "[epoch: 3, 2800] loss: 0.186\n",
            "[epoch: 3, 2900] loss: 0.199\n",
            "[epoch: 3, 3000] loss: 0.216\n",
            "[epoch: 3, 3100] loss: 0.188\n",
            "[epoch: 3, 3200] loss: 0.210\n",
            "[epoch: 3, 3300] loss: 0.264\n",
            "[epoch: 3, 3400] loss: 0.216\n",
            "[epoch: 3, 3500] loss: 0.262\n",
            "[epoch: 3, 3600] loss: 0.247\n",
            "[epoch: 3, 3700] loss: 0.188\n",
            "[epoch: 3, 3800] loss: 0.180\n",
            "[epoch: 3, 3900] loss: 0.187\n",
            "[epoch: 3, 4000] loss: 0.209\n",
            "[epoch: 3, 4100] loss: 0.242\n",
            "[epoch: 3, 4200] loss: 0.279\n",
            "[epoch: 3, 4300] loss: 0.231\n",
            "[epoch: 3, 4400] loss: 0.304\n",
            "[epoch: 3, 4500] loss: 0.175\n",
            "[epoch: 3, 4600] loss: 0.277\n",
            "[epoch: 3, 4700] loss: 0.194\n",
            "[epoch: 3, 4800] loss: 0.250\n",
            "[epoch: 3, 4900] loss: 0.213\n",
            "[epoch: 3, 5000] loss: 0.263\n",
            "[epoch: 3, 5100] loss: 0.168\n",
            "[epoch: 3, 5200] loss: 0.220\n",
            "[epoch: 3, 5300] loss: 0.180\n",
            "[epoch: 3, 5400] loss: 0.264\n",
            "[epoch: 3, 5500] loss: 0.270\n",
            "[epoch: 3, 5600] loss: 0.170\n",
            "[epoch: 3, 5700] loss: 0.231\n",
            "[epoch: 3, 5800] loss: 0.220\n",
            "[epoch: 3, 5900] loss: 0.251\n",
            "[epoch: 3, 6000] loss: 0.173\n",
            "[epoch: 4, 100] loss: 0.192\n",
            "[epoch: 4, 200] loss: 0.146\n",
            "[epoch: 4, 300] loss: 0.166\n",
            "[epoch: 4, 400] loss: 0.277\n",
            "[epoch: 4, 500] loss: 0.190\n",
            "[epoch: 4, 600] loss: 0.130\n",
            "[epoch: 4, 700] loss: 0.201\n",
            "[epoch: 4, 800] loss: 0.209\n",
            "[epoch: 4, 900] loss: 0.206\n",
            "[epoch: 4, 1000] loss: 0.223\n",
            "[epoch: 4, 1100] loss: 0.185\n",
            "[epoch: 4, 1200] loss: 0.250\n",
            "[epoch: 4, 1300] loss: 0.199\n",
            "[epoch: 4, 1400] loss: 0.236\n",
            "[epoch: 4, 1500] loss: 0.233\n",
            "[epoch: 4, 1600] loss: 0.253\n",
            "[epoch: 4, 1700] loss: 0.197\n",
            "[epoch: 4, 1800] loss: 0.210\n",
            "[epoch: 4, 1900] loss: 0.222\n",
            "[epoch: 4, 2000] loss: 0.217\n",
            "[epoch: 4, 2100] loss: 0.194\n",
            "[epoch: 4, 2200] loss: 0.186\n",
            "[epoch: 4, 2300] loss: 0.247\n",
            "[epoch: 4, 2400] loss: 0.195\n",
            "[epoch: 4, 2500] loss: 0.174\n",
            "[epoch: 4, 2600] loss: 0.217\n",
            "[epoch: 4, 2700] loss: 0.170\n",
            "[epoch: 4, 2800] loss: 0.209\n",
            "[epoch: 4, 2900] loss: 0.141\n",
            "[epoch: 4, 3000] loss: 0.231\n",
            "[epoch: 4, 3100] loss: 0.165\n",
            "[epoch: 4, 3200] loss: 0.190\n",
            "[epoch: 4, 3300] loss: 0.154\n",
            "[epoch: 4, 3400] loss: 0.241\n",
            "[epoch: 4, 3500] loss: 0.215\n",
            "[epoch: 4, 3600] loss: 0.206\n",
            "[epoch: 4, 3700] loss: 0.216\n",
            "[epoch: 4, 3800] loss: 0.172\n",
            "[epoch: 4, 3900] loss: 0.202\n",
            "[epoch: 4, 4000] loss: 0.169\n",
            "[epoch: 4, 4100] loss: 0.184\n",
            "[epoch: 4, 4200] loss: 0.257\n",
            "[epoch: 4, 4300] loss: 0.260\n",
            "[epoch: 4, 4400] loss: 0.150\n",
            "[epoch: 4, 4500] loss: 0.180\n",
            "[epoch: 4, 4600] loss: 0.191\n",
            "[epoch: 4, 4700] loss: 0.208\n",
            "[epoch: 4, 4800] loss: 0.192\n",
            "[epoch: 4, 4900] loss: 0.261\n",
            "[epoch: 4, 5000] loss: 0.224\n",
            "[epoch: 4, 5100] loss: 0.186\n",
            "[epoch: 4, 5200] loss: 0.206\n",
            "[epoch: 4, 5300] loss: 0.198\n",
            "[epoch: 4, 5400] loss: 0.195\n",
            "[epoch: 4, 5500] loss: 0.192\n",
            "[epoch: 4, 5600] loss: 0.168\n",
            "[epoch: 4, 5700] loss: 0.221\n",
            "[epoch: 4, 5800] loss: 0.195\n",
            "[epoch: 4, 5900] loss: 0.252\n",
            "[epoch: 4, 6000] loss: 0.237\n",
            "[epoch: 5, 100] loss: 0.203\n",
            "[epoch: 5, 200] loss: 0.180\n",
            "[epoch: 5, 300] loss: 0.143\n",
            "[epoch: 5, 400] loss: 0.155\n",
            "[epoch: 5, 500] loss: 0.181\n",
            "[epoch: 5, 600] loss: 0.168\n",
            "[epoch: 5, 700] loss: 0.213\n",
            "[epoch: 5, 800] loss: 0.196\n",
            "[epoch: 5, 900] loss: 0.179\n",
            "[epoch: 5, 1000] loss: 0.187\n",
            "[epoch: 5, 1100] loss: 0.195\n",
            "[epoch: 5, 1200] loss: 0.204\n",
            "[epoch: 5, 1300] loss: 0.238\n",
            "[epoch: 5, 1400] loss: 0.230\n",
            "[epoch: 5, 1500] loss: 0.194\n",
            "[epoch: 5, 1600] loss: 0.168\n",
            "[epoch: 5, 1700] loss: 0.220\n",
            "[epoch: 5, 1800] loss: 0.177\n",
            "[epoch: 5, 1900] loss: 0.188\n",
            "[epoch: 5, 2000] loss: 0.188\n",
            "[epoch: 5, 2100] loss: 0.153\n",
            "[epoch: 5, 2200] loss: 0.189\n",
            "[epoch: 5, 2300] loss: 0.190\n",
            "[epoch: 5, 2400] loss: 0.136\n",
            "[epoch: 5, 2500] loss: 0.174\n",
            "[epoch: 5, 2600] loss: 0.193\n",
            "[epoch: 5, 2700] loss: 0.197\n",
            "[epoch: 5, 2800] loss: 0.256\n",
            "[epoch: 5, 2900] loss: 0.196\n",
            "[epoch: 5, 3000] loss: 0.251\n",
            "[epoch: 5, 3100] loss: 0.220\n",
            "[epoch: 5, 3200] loss: 0.202\n",
            "[epoch: 5, 3300] loss: 0.224\n",
            "[epoch: 5, 3400] loss: 0.153\n",
            "[epoch: 5, 3500] loss: 0.230\n",
            "[epoch: 5, 3600] loss: 0.181\n",
            "[epoch: 5, 3700] loss: 0.228\n",
            "[epoch: 5, 3800] loss: 0.174\n",
            "[epoch: 5, 3900] loss: 0.147\n",
            "[epoch: 5, 4000] loss: 0.166\n",
            "[epoch: 5, 4100] loss: 0.196\n",
            "[epoch: 5, 4200] loss: 0.221\n",
            "[epoch: 5, 4300] loss: 0.160\n",
            "[epoch: 5, 4400] loss: 0.186\n",
            "[epoch: 5, 4500] loss: 0.183\n",
            "[epoch: 5, 4600] loss: 0.205\n",
            "[epoch: 5, 4700] loss: 0.192\n",
            "[epoch: 5, 4800] loss: 0.185\n",
            "[epoch: 5, 4900] loss: 0.190\n",
            "[epoch: 5, 5000] loss: 0.173\n",
            "[epoch: 5, 5100] loss: 0.223\n",
            "[epoch: 5, 5200] loss: 0.138\n",
            "[epoch: 5, 5300] loss: 0.186\n",
            "[epoch: 5, 5400] loss: 0.203\n",
            "[epoch: 5, 5500] loss: 0.163\n",
            "[epoch: 5, 5600] loss: 0.157\n",
            "[epoch: 5, 5700] loss: 0.117\n",
            "[epoch: 5, 5800] loss: 0.216\n",
            "[epoch: 5, 5900] loss: 0.149\n",
            "[epoch: 5, 6000] loss: 0.169\n",
            "Accuracy: 94.79%\n",
            "Model 2\n",
            "[epoch: 1, 100] loss: 1.963\n",
            "[epoch: 1, 200] loss: 1.054\n",
            "[epoch: 1, 300] loss: 0.719\n",
            "[epoch: 1, 400] loss: 0.587\n",
            "[epoch: 1, 500] loss: 0.476\n",
            "[epoch: 1, 600] loss: 0.468\n",
            "[epoch: 1, 700] loss: 0.431\n",
            "[epoch: 1, 800] loss: 0.390\n",
            "[epoch: 1, 900] loss: 0.504\n",
            "[epoch: 1, 1000] loss: 0.470\n",
            "[epoch: 1, 1100] loss: 0.449\n",
            "[epoch: 1, 1200] loss: 0.362\n",
            "[epoch: 1, 1300] loss: 0.323\n",
            "[epoch: 1, 1400] loss: 0.340\n",
            "[epoch: 1, 1500] loss: 0.387\n",
            "[epoch: 1, 1600] loss: 0.356\n",
            "[epoch: 1, 1700] loss: 0.358\n",
            "[epoch: 1, 1800] loss: 0.280\n",
            "[epoch: 1, 1900] loss: 0.340\n",
            "[epoch: 1, 2000] loss: 0.317\n",
            "[epoch: 1, 2100] loss: 0.303\n",
            "[epoch: 1, 2200] loss: 0.311\n",
            "[epoch: 1, 2300] loss: 0.366\n",
            "[epoch: 1, 2400] loss: 0.349\n",
            "[epoch: 1, 2500] loss: 0.313\n",
            "[epoch: 1, 2600] loss: 0.313\n",
            "[epoch: 1, 2700] loss: 0.307\n",
            "[epoch: 1, 2800] loss: 0.337\n",
            "[epoch: 1, 2900] loss: 0.301\n",
            "[epoch: 1, 3000] loss: 0.284\n",
            "[epoch: 1, 3100] loss: 0.299\n",
            "[epoch: 1, 3200] loss: 0.250\n",
            "[epoch: 1, 3300] loss: 0.249\n",
            "[epoch: 1, 3400] loss: 0.244\n",
            "[epoch: 1, 3500] loss: 0.282\n",
            "[epoch: 1, 3600] loss: 0.244\n",
            "[epoch: 1, 3700] loss: 0.326\n",
            "[epoch: 1, 3800] loss: 0.267\n",
            "[epoch: 1, 3900] loss: 0.291\n",
            "[epoch: 1, 4000] loss: 0.260\n",
            "[epoch: 1, 4100] loss: 0.223\n",
            "[epoch: 1, 4200] loss: 0.208\n",
            "[epoch: 1, 4300] loss: 0.256\n",
            "[epoch: 1, 4400] loss: 0.266\n",
            "[epoch: 1, 4500] loss: 0.221\n",
            "[epoch: 1, 4600] loss: 0.270\n",
            "[epoch: 1, 4700] loss: 0.209\n",
            "[epoch: 1, 4800] loss: 0.248\n",
            "[epoch: 1, 4900] loss: 0.250\n",
            "[epoch: 1, 5000] loss: 0.245\n",
            "[epoch: 1, 5100] loss: 0.210\n",
            "[epoch: 1, 5200] loss: 0.221\n",
            "[epoch: 1, 5300] loss: 0.210\n",
            "[epoch: 1, 5400] loss: 0.242\n",
            "[epoch: 1, 5500] loss: 0.207\n",
            "[epoch: 1, 5600] loss: 0.219\n",
            "[epoch: 1, 5700] loss: 0.214\n",
            "[epoch: 1, 5800] loss: 0.191\n",
            "[epoch: 1, 5900] loss: 0.207\n",
            "[epoch: 1, 6000] loss: 0.218\n",
            "[epoch: 2, 100] loss: 0.159\n",
            "[epoch: 2, 200] loss: 0.225\n",
            "[epoch: 2, 300] loss: 0.150\n",
            "[epoch: 2, 400] loss: 0.163\n",
            "[epoch: 2, 500] loss: 0.195\n",
            "[epoch: 2, 600] loss: 0.178\n",
            "[epoch: 2, 700] loss: 0.166\n",
            "[epoch: 2, 800] loss: 0.211\n",
            "[epoch: 2, 900] loss: 0.180\n",
            "[epoch: 2, 1000] loss: 0.191\n",
            "[epoch: 2, 1100] loss: 0.180\n",
            "[epoch: 2, 1200] loss: 0.167\n",
            "[epoch: 2, 1300] loss: 0.172\n",
            "[epoch: 2, 1400] loss: 0.156\n",
            "[epoch: 2, 1500] loss: 0.200\n",
            "[epoch: 2, 1600] loss: 0.207\n",
            "[epoch: 2, 1700] loss: 0.170\n",
            "[epoch: 2, 1800] loss: 0.205\n",
            "[epoch: 2, 1900] loss: 0.137\n",
            "[epoch: 2, 2000] loss: 0.169\n",
            "[epoch: 2, 2100] loss: 0.159\n",
            "[epoch: 2, 2200] loss: 0.196\n",
            "[epoch: 2, 2300] loss: 0.177\n",
            "[epoch: 2, 2400] loss: 0.169\n",
            "[epoch: 2, 2500] loss: 0.158\n",
            "[epoch: 2, 2600] loss: 0.178\n",
            "[epoch: 2, 2700] loss: 0.193\n",
            "[epoch: 2, 2800] loss: 0.200\n",
            "[epoch: 2, 2900] loss: 0.183\n",
            "[epoch: 2, 3000] loss: 0.162\n",
            "[epoch: 2, 3100] loss: 0.181\n",
            "[epoch: 2, 3200] loss: 0.155\n",
            "[epoch: 2, 3300] loss: 0.233\n",
            "[epoch: 2, 3400] loss: 0.165\n",
            "[epoch: 2, 3500] loss: 0.143\n",
            "[epoch: 2, 3600] loss: 0.138\n",
            "[epoch: 2, 3700] loss: 0.165\n",
            "[epoch: 2, 3800] loss: 0.159\n",
            "[epoch: 2, 3900] loss: 0.177\n",
            "[epoch: 2, 4000] loss: 0.135\n",
            "[epoch: 2, 4100] loss: 0.149\n",
            "[epoch: 2, 4200] loss: 0.175\n",
            "[epoch: 2, 4300] loss: 0.123\n",
            "[epoch: 2, 4400] loss: 0.146\n",
            "[epoch: 2, 4500] loss: 0.170\n",
            "[epoch: 2, 4600] loss: 0.147\n",
            "[epoch: 2, 4700] loss: 0.167\n",
            "[epoch: 2, 4800] loss: 0.166\n",
            "[epoch: 2, 4900] loss: 0.156\n",
            "[epoch: 2, 5000] loss: 0.180\n",
            "[epoch: 2, 5100] loss: 0.142\n",
            "[epoch: 2, 5200] loss: 0.189\n",
            "[epoch: 2, 5300] loss: 0.181\n",
            "[epoch: 2, 5400] loss: 0.161\n",
            "[epoch: 2, 5500] loss: 0.126\n",
            "[epoch: 2, 5600] loss: 0.138\n",
            "[epoch: 2, 5700] loss: 0.166\n",
            "[epoch: 2, 5800] loss: 0.142\n",
            "[epoch: 2, 5900] loss: 0.160\n",
            "[epoch: 2, 6000] loss: 0.165\n",
            "[epoch: 3, 100] loss: 0.117\n",
            "[epoch: 3, 200] loss: 0.124\n",
            "[epoch: 3, 300] loss: 0.130\n",
            "[epoch: 3, 400] loss: 0.148\n",
            "[epoch: 3, 500] loss: 0.133\n",
            "[epoch: 3, 600] loss: 0.128\n",
            "[epoch: 3, 700] loss: 0.120\n",
            "[epoch: 3, 800] loss: 0.120\n",
            "[epoch: 3, 900] loss: 0.121\n",
            "[epoch: 3, 1000] loss: 0.161\n",
            "[epoch: 3, 1100] loss: 0.113\n",
            "[epoch: 3, 1200] loss: 0.139\n",
            "[epoch: 3, 1300] loss: 0.098\n",
            "[epoch: 3, 1400] loss: 0.116\n",
            "[epoch: 3, 1500] loss: 0.117\n",
            "[epoch: 3, 1600] loss: 0.137\n",
            "[epoch: 3, 1700] loss: 0.137\n",
            "[epoch: 3, 1800] loss: 0.149\n",
            "[epoch: 3, 1900] loss: 0.112\n",
            "[epoch: 3, 2000] loss: 0.102\n",
            "[epoch: 3, 2100] loss: 0.169\n",
            "[epoch: 3, 2200] loss: 0.071\n",
            "[epoch: 3, 2300] loss: 0.166\n",
            "[epoch: 3, 2400] loss: 0.132\n",
            "[epoch: 3, 2500] loss: 0.152\n",
            "[epoch: 3, 2600] loss: 0.124\n",
            "[epoch: 3, 2700] loss: 0.130\n",
            "[epoch: 3, 2800] loss: 0.169\n",
            "[epoch: 3, 2900] loss: 0.116\n",
            "[epoch: 3, 3000] loss: 0.139\n",
            "[epoch: 3, 3100] loss: 0.122\n",
            "[epoch: 3, 3200] loss: 0.150\n",
            "[epoch: 3, 3300] loss: 0.141\n",
            "[epoch: 3, 3400] loss: 0.124\n",
            "[epoch: 3, 3500] loss: 0.136\n",
            "[epoch: 3, 3600] loss: 0.150\n",
            "[epoch: 3, 3700] loss: 0.104\n",
            "[epoch: 3, 3800] loss: 0.133\n",
            "[epoch: 3, 3900] loss: 0.106\n",
            "[epoch: 3, 4000] loss: 0.118\n",
            "[epoch: 3, 4100] loss: 0.128\n",
            "[epoch: 3, 4200] loss: 0.126\n",
            "[epoch: 3, 4300] loss: 0.119\n",
            "[epoch: 3, 4400] loss: 0.105\n",
            "[epoch: 3, 4500] loss: 0.106\n",
            "[epoch: 3, 4600] loss: 0.126\n",
            "[epoch: 3, 4700] loss: 0.116\n",
            "[epoch: 3, 4800] loss: 0.140\n",
            "[epoch: 3, 4900] loss: 0.104\n",
            "[epoch: 3, 5000] loss: 0.099\n",
            "[epoch: 3, 5100] loss: 0.138\n",
            "[epoch: 3, 5200] loss: 0.113\n",
            "[epoch: 3, 5300] loss: 0.119\n",
            "[epoch: 3, 5400] loss: 0.105\n",
            "[epoch: 3, 5500] loss: 0.121\n",
            "[epoch: 3, 5600] loss: 0.087\n",
            "[epoch: 3, 5700] loss: 0.101\n",
            "[epoch: 3, 5800] loss: 0.109\n",
            "[epoch: 3, 5900] loss: 0.107\n",
            "[epoch: 3, 6000] loss: 0.107\n",
            "[epoch: 4, 100] loss: 0.097\n",
            "[epoch: 4, 200] loss: 0.094\n",
            "[epoch: 4, 300] loss: 0.089\n",
            "[epoch: 4, 400] loss: 0.112\n",
            "[epoch: 4, 500] loss: 0.100\n",
            "[epoch: 4, 600] loss: 0.075\n",
            "[epoch: 4, 700] loss: 0.136\n",
            "[epoch: 4, 800] loss: 0.096\n",
            "[epoch: 4, 900] loss: 0.106\n",
            "[epoch: 4, 1000] loss: 0.112\n",
            "[epoch: 4, 1100] loss: 0.121\n",
            "[epoch: 4, 1200] loss: 0.105\n",
            "[epoch: 4, 1300] loss: 0.096\n",
            "[epoch: 4, 1400] loss: 0.089\n",
            "[epoch: 4, 1500] loss: 0.110\n",
            "[epoch: 4, 1600] loss: 0.097\n",
            "[epoch: 4, 1700] loss: 0.122\n",
            "[epoch: 4, 1800] loss: 0.115\n",
            "[epoch: 4, 1900] loss: 0.070\n",
            "[epoch: 4, 2000] loss: 0.088\n",
            "[epoch: 4, 2100] loss: 0.092\n",
            "[epoch: 4, 2200] loss: 0.106\n",
            "[epoch: 4, 2300] loss: 0.092\n",
            "[epoch: 4, 2400] loss: 0.098\n",
            "[epoch: 4, 2500] loss: 0.091\n",
            "[epoch: 4, 2600] loss: 0.109\n",
            "[epoch: 4, 2700] loss: 0.105\n",
            "[epoch: 4, 2800] loss: 0.100\n",
            "[epoch: 4, 2900] loss: 0.114\n",
            "[epoch: 4, 3000] loss: 0.088\n",
            "[epoch: 4, 3100] loss: 0.098\n",
            "[epoch: 4, 3200] loss: 0.089\n",
            "[epoch: 4, 3300] loss: 0.085\n",
            "[epoch: 4, 3400] loss: 0.105\n",
            "[epoch: 4, 3500] loss: 0.081\n",
            "[epoch: 4, 3600] loss: 0.126\n",
            "[epoch: 4, 3700] loss: 0.106\n",
            "[epoch: 4, 3800] loss: 0.096\n",
            "[epoch: 4, 3900] loss: 0.128\n",
            "[epoch: 4, 4000] loss: 0.118\n",
            "[epoch: 4, 4100] loss: 0.108\n",
            "[epoch: 4, 4200] loss: 0.090\n",
            "[epoch: 4, 4300] loss: 0.098\n",
            "[epoch: 4, 4400] loss: 0.089\n",
            "[epoch: 4, 4500] loss: 0.078\n",
            "[epoch: 4, 4600] loss: 0.114\n",
            "[epoch: 4, 4700] loss: 0.079\n",
            "[epoch: 4, 4800] loss: 0.108\n",
            "[epoch: 4, 4900] loss: 0.116\n",
            "[epoch: 4, 5000] loss: 0.095\n",
            "[epoch: 4, 5100] loss: 0.092\n",
            "[epoch: 4, 5200] loss: 0.111\n",
            "[epoch: 4, 5300] loss: 0.073\n",
            "[epoch: 4, 5400] loss: 0.083\n",
            "[epoch: 4, 5500] loss: 0.114\n",
            "[epoch: 4, 5600] loss: 0.107\n",
            "[epoch: 4, 5700] loss: 0.120\n",
            "[epoch: 4, 5800] loss: 0.096\n",
            "[epoch: 4, 5900] loss: 0.111\n",
            "[epoch: 4, 6000] loss: 0.096\n",
            "[epoch: 5, 100] loss: 0.094\n",
            "[epoch: 5, 200] loss: 0.097\n",
            "[epoch: 5, 300] loss: 0.064\n",
            "[epoch: 5, 400] loss: 0.083\n",
            "[epoch: 5, 500] loss: 0.056\n",
            "[epoch: 5, 600] loss: 0.088\n",
            "[epoch: 5, 700] loss: 0.095\n",
            "[epoch: 5, 800] loss: 0.111\n",
            "[epoch: 5, 900] loss: 0.080\n",
            "[epoch: 5, 1000] loss: 0.079\n",
            "[epoch: 5, 1100] loss: 0.073\n",
            "[epoch: 5, 1200] loss: 0.077\n",
            "[epoch: 5, 1300] loss: 0.091\n",
            "[epoch: 5, 1400] loss: 0.077\n",
            "[epoch: 5, 1500] loss: 0.087\n",
            "[epoch: 5, 1600] loss: 0.059\n",
            "[epoch: 5, 1700] loss: 0.074\n",
            "[epoch: 5, 1800] loss: 0.067\n",
            "[epoch: 5, 1900] loss: 0.084\n",
            "[epoch: 5, 2000] loss: 0.052\n",
            "[epoch: 5, 2100] loss: 0.068\n",
            "[epoch: 5, 2200] loss: 0.061\n",
            "[epoch: 5, 2300] loss: 0.097\n",
            "[epoch: 5, 2400] loss: 0.077\n",
            "[epoch: 5, 2500] loss: 0.093\n",
            "[epoch: 5, 2600] loss: 0.086\n",
            "[epoch: 5, 2700] loss: 0.086\n",
            "[epoch: 5, 2800] loss: 0.086\n",
            "[epoch: 5, 2900] loss: 0.081\n",
            "[epoch: 5, 3000] loss: 0.073\n",
            "[epoch: 5, 3100] loss: 0.086\n",
            "[epoch: 5, 3200] loss: 0.077\n",
            "[epoch: 5, 3300] loss: 0.087\n",
            "[epoch: 5, 3400] loss: 0.087\n",
            "[epoch: 5, 3500] loss: 0.083\n",
            "[epoch: 5, 3600] loss: 0.095\n",
            "[epoch: 5, 3700] loss: 0.115\n",
            "[epoch: 5, 3800] loss: 0.086\n",
            "[epoch: 5, 3900] loss: 0.109\n",
            "[epoch: 5, 4000] loss: 0.079\n",
            "[epoch: 5, 4100] loss: 0.096\n",
            "[epoch: 5, 4200] loss: 0.101\n",
            "[epoch: 5, 4300] loss: 0.091\n",
            "[epoch: 5, 4400] loss: 0.102\n",
            "[epoch: 5, 4500] loss: 0.099\n",
            "[epoch: 5, 4600] loss: 0.089\n",
            "[epoch: 5, 4700] loss: 0.066\n",
            "[epoch: 5, 4800] loss: 0.070\n",
            "[epoch: 5, 4900] loss: 0.094\n",
            "[epoch: 5, 5000] loss: 0.091\n",
            "[epoch: 5, 5100] loss: 0.089\n",
            "[epoch: 5, 5200] loss: 0.102\n",
            "[epoch: 5, 5300] loss: 0.055\n",
            "[epoch: 5, 5400] loss: 0.090\n",
            "[epoch: 5, 5500] loss: 0.088\n",
            "[epoch: 5, 5600] loss: 0.078\n",
            "[epoch: 5, 5700] loss: 0.081\n",
            "[epoch: 5, 5800] loss: 0.077\n",
            "[epoch: 5, 5900] loss: 0.062\n",
            "[epoch: 5, 6000] loss: 0.097\n",
            "Accuracy: 97.11%\n",
            "Model 3\n",
            "[epoch: 1, 100] loss: 2.303\n",
            "[epoch: 1, 200] loss: 2.299\n",
            "[epoch: 1, 300] loss: 2.291\n",
            "[epoch: 1, 400] loss: 2.207\n",
            "[epoch: 1, 500] loss: 2.072\n",
            "[epoch: 1, 600] loss: 1.932\n",
            "[epoch: 1, 700] loss: 1.817\n",
            "[epoch: 1, 800] loss: 1.779\n",
            "[epoch: 1, 900] loss: 1.770\n",
            "[epoch: 1, 1000] loss: 1.725\n",
            "[epoch: 1, 1100] loss: 1.790\n",
            "[epoch: 1, 1200] loss: 1.745\n",
            "[epoch: 1, 1300] loss: 1.683\n",
            "[epoch: 1, 1400] loss: 1.658\n",
            "[epoch: 1, 1500] loss: 1.673\n",
            "[epoch: 1, 1600] loss: 1.620\n",
            "[epoch: 1, 1700] loss: 1.613\n",
            "[epoch: 1, 1800] loss: 1.605\n",
            "[epoch: 1, 1900] loss: 1.567\n",
            "[epoch: 1, 2000] loss: 1.552\n",
            "[epoch: 1, 2100] loss: 1.566\n",
            "[epoch: 1, 2200] loss: 1.524\n",
            "[epoch: 1, 2300] loss: 1.513\n",
            "[epoch: 1, 2400] loss: 1.436\n",
            "[epoch: 1, 2500] loss: 1.470\n",
            "[epoch: 1, 2600] loss: 1.444\n",
            "[epoch: 1, 2700] loss: 1.430\n",
            "[epoch: 1, 2800] loss: 1.378\n",
            "[epoch: 1, 2900] loss: 1.417\n",
            "[epoch: 1, 3000] loss: 1.389\n",
            "[epoch: 1, 3100] loss: 1.370\n",
            "[epoch: 1, 3200] loss: 1.444\n",
            "[epoch: 1, 3300] loss: 1.355\n",
            "[epoch: 1, 3400] loss: 1.316\n",
            "[epoch: 1, 3500] loss: 1.359\n",
            "[epoch: 1, 3600] loss: 1.404\n",
            "[epoch: 1, 3700] loss: 1.328\n",
            "[epoch: 1, 3800] loss: 1.380\n",
            "[epoch: 1, 3900] loss: 1.335\n",
            "[epoch: 1, 4000] loss: 1.348\n",
            "[epoch: 1, 4100] loss: 1.293\n",
            "[epoch: 1, 4200] loss: 1.253\n",
            "[epoch: 1, 4300] loss: 1.252\n",
            "[epoch: 1, 4400] loss: 1.209\n",
            "[epoch: 1, 4500] loss: 1.255\n",
            "[epoch: 1, 4600] loss: 1.247\n",
            "[epoch: 1, 4700] loss: 1.200\n",
            "[epoch: 1, 4800] loss: 1.207\n",
            "[epoch: 1, 4900] loss: 1.250\n",
            "[epoch: 1, 5000] loss: 1.179\n",
            "[epoch: 1, 5100] loss: 1.262\n",
            "[epoch: 1, 5200] loss: 1.255\n",
            "[epoch: 1, 5300] loss: 1.199\n",
            "[epoch: 1, 5400] loss: 1.183\n",
            "[epoch: 1, 5500] loss: 1.191\n",
            "[epoch: 1, 5600] loss: 1.160\n",
            "[epoch: 1, 5700] loss: 1.193\n",
            "[epoch: 1, 5800] loss: 1.210\n",
            "[epoch: 1, 5900] loss: 1.173\n",
            "[epoch: 1, 6000] loss: 1.157\n",
            "[epoch: 2, 100] loss: 1.153\n",
            "[epoch: 2, 200] loss: 1.228\n",
            "[epoch: 2, 300] loss: 1.198\n",
            "[epoch: 2, 400] loss: 1.143\n",
            "[epoch: 2, 500] loss: 1.159\n",
            "[epoch: 2, 600] loss: 1.182\n",
            "[epoch: 2, 700] loss: 1.164\n",
            "[epoch: 2, 800] loss: 1.148\n",
            "[epoch: 2, 900] loss: 1.172\n",
            "[epoch: 2, 1000] loss: 1.150\n",
            "[epoch: 2, 1100] loss: 1.240\n",
            "[epoch: 2, 1200] loss: 1.152\n",
            "[epoch: 2, 1300] loss: 1.188\n",
            "[epoch: 2, 1400] loss: 1.167\n",
            "[epoch: 2, 1500] loss: 1.164\n",
            "[epoch: 2, 1600] loss: 1.150\n",
            "[epoch: 2, 1700] loss: 1.144\n",
            "[epoch: 2, 1800] loss: 1.158\n",
            "[epoch: 2, 1900] loss: 1.120\n",
            "[epoch: 2, 2000] loss: 1.136\n",
            "[epoch: 2, 2100] loss: 1.137\n",
            "[epoch: 2, 2200] loss: 1.150\n",
            "[epoch: 2, 2300] loss: 1.126\n",
            "[epoch: 2, 2400] loss: 1.120\n",
            "[epoch: 2, 2500] loss: 1.165\n",
            "[epoch: 2, 2600] loss: 1.157\n",
            "[epoch: 2, 2700] loss: 1.070\n",
            "[epoch: 2, 2800] loss: 1.092\n",
            "[epoch: 2, 2900] loss: 1.100\n",
            "[epoch: 2, 3000] loss: 1.152\n",
            "[epoch: 2, 3100] loss: 1.118\n",
            "[epoch: 2, 3200] loss: 1.183\n",
            "[epoch: 2, 3300] loss: 1.110\n",
            "[epoch: 2, 3400] loss: 1.081\n",
            "[epoch: 2, 3500] loss: 1.091\n",
            "[epoch: 2, 3600] loss: 1.089\n",
            "[epoch: 2, 3700] loss: 1.104\n",
            "[epoch: 2, 3800] loss: 1.139\n",
            "[epoch: 2, 3900] loss: 1.024\n",
            "[epoch: 2, 4000] loss: 0.958\n",
            "[epoch: 2, 4100] loss: 1.014\n",
            "[epoch: 2, 4200] loss: 1.005\n",
            "[epoch: 2, 4300] loss: 0.961\n",
            "[epoch: 2, 4400] loss: 0.921\n",
            "[epoch: 2, 4500] loss: 0.979\n",
            "[epoch: 2, 4600] loss: 0.988\n",
            "[epoch: 2, 4700] loss: 0.967\n",
            "[epoch: 2, 4800] loss: 0.958\n",
            "[epoch: 2, 4900] loss: 0.947\n",
            "[epoch: 2, 5000] loss: 0.940\n",
            "[epoch: 2, 5100] loss: 0.940\n",
            "[epoch: 2, 5200] loss: 0.957\n",
            "[epoch: 2, 5300] loss: 0.942\n",
            "[epoch: 2, 5400] loss: 0.930\n",
            "[epoch: 2, 5500] loss: 0.991\n",
            "[epoch: 2, 5600] loss: 0.925\n",
            "[epoch: 2, 5700] loss: 0.908\n",
            "[epoch: 2, 5800] loss: 0.951\n",
            "[epoch: 2, 5900] loss: 0.881\n",
            "[epoch: 2, 6000] loss: 0.947\n",
            "[epoch: 3, 100] loss: 0.902\n",
            "[epoch: 3, 200] loss: 0.912\n",
            "[epoch: 3, 300] loss: 0.939\n",
            "[epoch: 3, 400] loss: 0.885\n",
            "[epoch: 3, 500] loss: 0.882\n",
            "[epoch: 3, 600] loss: 0.858\n",
            "[epoch: 3, 700] loss: 0.861\n",
            "[epoch: 3, 800] loss: 0.845\n",
            "[epoch: 3, 900] loss: 0.828\n",
            "[epoch: 3, 1000] loss: 0.896\n",
            "[epoch: 3, 1100] loss: 0.862\n",
            "[epoch: 3, 1200] loss: 0.888\n",
            "[epoch: 3, 1300] loss: 0.784\n",
            "[epoch: 3, 1400] loss: 0.843\n",
            "[epoch: 3, 1500] loss: 0.865\n",
            "[epoch: 3, 1600] loss: 0.777\n",
            "[epoch: 3, 1700] loss: 0.875\n",
            "[epoch: 3, 1800] loss: 0.791\n",
            "[epoch: 3, 1900] loss: 0.795\n",
            "[epoch: 3, 2000] loss: 0.778\n",
            "[epoch: 3, 2100] loss: 0.797\n",
            "[epoch: 3, 2200] loss: 0.743\n",
            "[epoch: 3, 2300] loss: 0.772\n",
            "[epoch: 3, 2400] loss: 0.822\n",
            "[epoch: 3, 2500] loss: 0.824\n",
            "[epoch: 3, 2600] loss: 0.748\n",
            "[epoch: 3, 2700] loss: 0.855\n",
            "[epoch: 3, 2800] loss: 0.799\n",
            "[epoch: 3, 2900] loss: 0.748\n",
            "[epoch: 3, 3000] loss: 0.790\n",
            "[epoch: 3, 3100] loss: 0.833\n",
            "[epoch: 3, 3200] loss: 0.813\n",
            "[epoch: 3, 3300] loss: 0.756\n",
            "[epoch: 3, 3400] loss: 0.835\n",
            "[epoch: 3, 3500] loss: 0.842\n",
            "[epoch: 3, 3600] loss: 0.760\n",
            "[epoch: 3, 3700] loss: 0.816\n",
            "[epoch: 3, 3800] loss: 0.758\n",
            "[epoch: 3, 3900] loss: 0.743\n",
            "[epoch: 3, 4000] loss: 0.740\n",
            "[epoch: 3, 4100] loss: 0.795\n",
            "[epoch: 3, 4200] loss: 0.791\n",
            "[epoch: 3, 4300] loss: 0.769\n",
            "[epoch: 3, 4400] loss: 0.826\n",
            "[epoch: 3, 4500] loss: 0.845\n",
            "[epoch: 3, 4600] loss: 0.768\n",
            "[epoch: 3, 4700] loss: 0.727\n",
            "[epoch: 3, 4800] loss: 0.730\n",
            "[epoch: 3, 4900] loss: 0.760\n",
            "[epoch: 3, 5000] loss: 0.782\n",
            "[epoch: 3, 5100] loss: 0.766\n",
            "[epoch: 3, 5200] loss: 0.774\n",
            "[epoch: 3, 5300] loss: 0.793\n",
            "[epoch: 3, 5400] loss: 0.791\n",
            "[epoch: 3, 5500] loss: 0.748\n",
            "[epoch: 3, 5600] loss: 0.785\n",
            "[epoch: 3, 5700] loss: 0.770\n",
            "[epoch: 3, 5800] loss: 0.760\n",
            "[epoch: 3, 5900] loss: 0.753\n",
            "[epoch: 3, 6000] loss: 0.804\n",
            "[epoch: 4, 100] loss: 0.848\n",
            "[epoch: 4, 200] loss: 0.728\n",
            "[epoch: 4, 300] loss: 0.792\n",
            "[epoch: 4, 400] loss: 0.766\n",
            "[epoch: 4, 500] loss: 0.740\n",
            "[epoch: 4, 600] loss: 0.720\n",
            "[epoch: 4, 700] loss: 0.692\n",
            "[epoch: 4, 800] loss: 0.760\n",
            "[epoch: 4, 900] loss: 0.772\n",
            "[epoch: 4, 1000] loss: 0.754\n",
            "[epoch: 4, 1100] loss: 0.778\n",
            "[epoch: 4, 1200] loss: 0.828\n",
            "[epoch: 4, 1300] loss: 0.710\n",
            "[epoch: 4, 1400] loss: 0.737\n",
            "[epoch: 4, 1500] loss: 0.750\n",
            "[epoch: 4, 1600] loss: 0.777\n",
            "[epoch: 4, 1700] loss: 0.790\n",
            "[epoch: 4, 1800] loss: 0.713\n",
            "[epoch: 4, 1900] loss: 0.739\n",
            "[epoch: 4, 2000] loss: 0.794\n",
            "[epoch: 4, 2100] loss: 0.719\n",
            "[epoch: 4, 2200] loss: 0.734\n",
            "[epoch: 4, 2300] loss: 0.776\n",
            "[epoch: 4, 2400] loss: 0.747\n",
            "[epoch: 4, 2500] loss: 0.721\n",
            "[epoch: 4, 2600] loss: 0.778\n",
            "[epoch: 4, 2700] loss: 0.748\n",
            "[epoch: 4, 2800] loss: 0.692\n",
            "[epoch: 4, 2900] loss: 0.754\n",
            "[epoch: 4, 3000] loss: 0.689\n",
            "[epoch: 4, 3100] loss: 0.664\n",
            "[epoch: 4, 3200] loss: 0.710\n",
            "[epoch: 4, 3300] loss: 0.657\n",
            "[epoch: 4, 3400] loss: 0.733\n",
            "[epoch: 4, 3500] loss: 0.734\n",
            "[epoch: 4, 3600] loss: 0.695\n",
            "[epoch: 4, 3700] loss: 0.695\n",
            "[epoch: 4, 3800] loss: 0.790\n",
            "[epoch: 4, 3900] loss: 0.764\n",
            "[epoch: 4, 4000] loss: 0.717\n",
            "[epoch: 4, 4100] loss: 0.715\n",
            "[epoch: 4, 4200] loss: 0.757\n",
            "[epoch: 4, 4300] loss: 0.731\n",
            "[epoch: 4, 4400] loss: 0.713\n",
            "[epoch: 4, 4500] loss: 0.708\n",
            "[epoch: 4, 4600] loss: 0.776\n",
            "[epoch: 4, 4700] loss: 0.754\n",
            "[epoch: 4, 4800] loss: 0.755\n",
            "[epoch: 4, 4900] loss: 0.707\n",
            "[epoch: 4, 5000] loss: 0.748\n",
            "[epoch: 4, 5100] loss: 0.676\n",
            "[epoch: 4, 5200] loss: 0.728\n",
            "[epoch: 4, 5300] loss: 0.723\n",
            "[epoch: 4, 5400] loss: 0.700\n",
            "[epoch: 4, 5500] loss: 0.764\n",
            "[epoch: 4, 5600] loss: 0.788\n",
            "[epoch: 4, 5700] loss: 0.736\n",
            "[epoch: 4, 5800] loss: 0.785\n",
            "[epoch: 4, 5900] loss: 0.749\n",
            "[epoch: 4, 6000] loss: 0.722\n",
            "[epoch: 5, 100] loss: 0.762\n",
            "[epoch: 5, 200] loss: 0.722\n",
            "[epoch: 5, 300] loss: 0.720\n",
            "[epoch: 5, 400] loss: 0.691\n",
            "[epoch: 5, 500] loss: 0.772\n",
            "[epoch: 5, 600] loss: 0.672\n",
            "[epoch: 5, 700] loss: 0.687\n",
            "[epoch: 5, 800] loss: 0.801\n",
            "[epoch: 5, 900] loss: 0.744\n",
            "[epoch: 5, 1000] loss: 0.744\n",
            "[epoch: 5, 1100] loss: 0.674\n",
            "[epoch: 5, 1200] loss: 0.754\n",
            "[epoch: 5, 1300] loss: 0.733\n",
            "[epoch: 5, 1400] loss: 0.783\n",
            "[epoch: 5, 1500] loss: 0.738\n",
            "[epoch: 5, 1600] loss: 0.716\n",
            "[epoch: 5, 1700] loss: 0.717\n",
            "[epoch: 5, 1800] loss: 0.791\n",
            "[epoch: 5, 1900] loss: 0.693\n",
            "[epoch: 5, 2000] loss: 0.786\n",
            "[epoch: 5, 2100] loss: 0.776\n",
            "[epoch: 5, 2200] loss: 0.712\n",
            "[epoch: 5, 2300] loss: 0.718\n",
            "[epoch: 5, 2400] loss: 0.736\n",
            "[epoch: 5, 2500] loss: 0.735\n",
            "[epoch: 5, 2600] loss: 0.745\n",
            "[epoch: 5, 2700] loss: 0.710\n",
            "[epoch: 5, 2800] loss: 0.723\n",
            "[epoch: 5, 2900] loss: 0.696\n",
            "[epoch: 5, 3000] loss: 0.704\n",
            "[epoch: 5, 3100] loss: 0.761\n",
            "[epoch: 5, 3200] loss: 0.689\n",
            "[epoch: 5, 3300] loss: 0.700\n",
            "[epoch: 5, 3400] loss: 0.741\n",
            "[epoch: 5, 3500] loss: 0.634\n",
            "[epoch: 5, 3600] loss: 0.724\n",
            "[epoch: 5, 3700] loss: 0.697\n",
            "[epoch: 5, 3800] loss: 0.715\n",
            "[epoch: 5, 3900] loss: 0.687\n",
            "[epoch: 5, 4000] loss: 0.760\n",
            "[epoch: 5, 4100] loss: 0.823\n",
            "[epoch: 5, 4200] loss: 0.767\n",
            "[epoch: 5, 4300] loss: 0.736\n",
            "[epoch: 5, 4400] loss: 0.705\n",
            "[epoch: 5, 4500] loss: 0.705\n",
            "[epoch: 5, 4600] loss: 0.650\n",
            "[epoch: 5, 4700] loss: 0.671\n",
            "[epoch: 5, 4800] loss: 0.672\n",
            "[epoch: 5, 4900] loss: 0.627\n",
            "[epoch: 5, 5000] loss: 0.696\n",
            "[epoch: 5, 5100] loss: 0.702\n",
            "[epoch: 5, 5200] loss: 0.746\n",
            "[epoch: 5, 5300] loss: 0.771\n",
            "[epoch: 5, 5400] loss: 0.774\n",
            "[epoch: 5, 5500] loss: 0.729\n",
            "[epoch: 5, 5600] loss: 0.709\n",
            "[epoch: 5, 5700] loss: 0.719\n",
            "[epoch: 5, 5800] loss: 0.673\n",
            "[epoch: 5, 5900] loss: 0.680\n",
            "[epoch: 5, 6000] loss: 0.757\n",
            "Accuracy: 73.44%\n",
            "Accurate: [94.79, 97.11, 73.44]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the results of the three models above with different activation functions, we get an accuracy of :\n",
        "\n",
        "* ReLU activation function = 94.79%\n",
        "* Sigmoid activation function = 97.11%\n",
        "* Softmax activation function = 73.44%\n",
        "\n",
        "From the evaluation results of the three models above, it can be concluded that the model that uses the sigmoid activation function provides the best performance results with an accuracy of 97.11%, while the model that uses the ReLU activation function provides results with an accuracy of 94.79%, and the model that uses the Softmax activation gives the worst performance results with an accuracy of 73.44%. This proves that the choice of activation function can influence model performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "DX2MuV5f-FF0"
      }
    }
  ]
}